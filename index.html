<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <title>Jinghao Zhou's homepage</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Le styles -->
    <link href="./css/bootstrap.min.css" rel="stylesheet">
    <link href="./css/bootstrap-responsive.min.css" rel="stylesheet">
    <link href="./css/main.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
    <script src="assets/js/html5shiv.js"></script>
    <![endif]-->
    <link rel="icon" href="./assets/ico/favicon.ico">
</head>

<div class="visible-phone" id='blackBar'>
        <a href="#top">Bio  </a>
        <a href="#publications">Publications  </a>
        <a href="#projects">Projects  </a>
        <a href="#reseachinterests">Research Interests </a>
        <a target="_blank" href="https://drive.google.com/open?id=1E13QoksnLJdSM6pRwLiHcXQGzufhyW89">CV</a>
</div>

<body>

<div class="container span3 hidden-phone">
    <div id="floating_sidebar" class="span3">
        <!-- We use a fancy nav bar if there is enough space -->
        <!--<hr class="hidden-phone">-->
        <br>
        <ul class="nav nav-list bs-docs-sidenav hidden-phone">
            <li><a href="#top">Bio  </a></li>
            <li><a href="#publications">Publications  </a></li>
            <li><a href="#projects">Projects  </a></li>
            <li><a href="#reseachinterests">Research Interests  </a></li>
            <li><a target="_blank" href="https://drive.google.com/open?id=1E13QoksnLJdSM6pRwLiHcXQGzufhyW89">CV</a>
            </li>
        </ul>
        <hr class="hidden-phone">
        <div class="text-center hidden-phone">
            <img src="assets/ico/me.png" alt="photo" class="logo-image"><br><br>
            <p> Email: jensen zhoujh at gmail com</p>
        </div>

        <!-- Otherwise, we simply use a flat list of links -->
        <div id="footer">
        	<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=080808&w=250&t=tt&d=SuyMPMY6OOgAhEdXDS6Xlc-HXmnw9Yb5sLKpDuhtW4s&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080"></script>
    	</div>
    </div>
</div>


<div class="container">

    <div class="row">

        <div class="span9">
            <div id="toptitle">
	            <h1>Jinghao Zhou
	                <div style="float:right">
	                	<a href="https://github.com/shallowtoil"><img src="./assets/ico/GitHub-Mark.png" width="32px"></a>
	                	<a href="https://www.linkedin.com/in/jensenzhoujh/"><img src="./assets/ico/linkedin.png" width="22px"></a>
	                	<a href="https://www.zhihu.com/people/jensen.zhoujh/"><img src="./assets/ico/cssi_zhihu-512.png" width="22px"></a>
	                    <a href="https://instagram.com/jensenzhoujh"><img src="./assets/ico/ins.png" width="30px"></a>
	                    <a href="https://www.youtube.com/channel/UC9qa5a404zaVi2yK3qENlfQ"><img src="./assets/ico/youtube.png" width="28px"></a>
	                    <a href="https://twitter.com/jensenzhoujh"><img src="./assets/ico/twitter.png" width="28px"></a>
	                </div>
            	</h1>
        	</div>
            <!-- Do I want to show a pic on the phone screen?
            <div class="text-center visible-phone">
                <img src="assets/img/Yihui.png" alt="photo" width="150px"/>
            </div>
            -->
            <a class="visible-phone pull-left" href="http://daggerfs.com/index.html#">
                <img class="media-object" src="assets/ico/me.png" width="96px" style="margin: 0px 10px">
            </a>

            <p>
                I'm an undergraduate student at <a target="_blank" href="https://www.nwpu.edu.cn/">Northwestern Polytechnical University</a>. Currently I'm a research intern in <a target="_blank" href="http://kypt.nwpu.edu.cn/index.php?c=content&a=show&id=288">Key Laboratory of Speech and Image Processing</a> under the supervision of Prof. <a target="_blank" href="http://teacher.nwpu.edu.cn/pengwang.html">Peng Wang</a>.
            </p>
            
            <!--
            <p>
                During my undergrad study I was fortunate to be an intern with <a target="_blank" href="http://jiansun.org/">Jian Sun</a> (Megvii/Face++), <a target="_blank" href="http://songhan.mit.edu">Song Han</a> (MIT) and <a target="_blank" href="http://www.cs.jhu.edu/~ayuille/">Alan Yuille</a> (JHU). I have a track record of contributing to CNN efficient inference. 
            Particularly, I designed <a href="#cp">channel pruning</a> to effectively prune channels. 
            I further proposed <a href="#AMC">AMC</a> to sample the design space of channel pruning via reinforcement learning, which greatly improved the performance.
             <!/p>  
            <p>I served as a reviewer for CVPR'19, ICLR'19, NIPS'18 and TIP. </p>
            -->
            
            <div class="infoblock">
            	<p> NEWS: I'm now looking for part-time intership.</p>
            </div>

            <!--
             *** Publications ***
            -->
            <h3>
                <a name="publications"></a> Publications
            </h3>

			<h4>Conference and Journals</h4>
            <div class="media">
                <div class="media-body">
                	<p>2020</p>
                	<ul><li><p class="media-heading">
                        <strong>
                             Discriminative and Robust Online Learning for Siamese Visual Tracking
                        </strong>
                        [<a target="_blank"
                           href="https://arxiv.org/abs/1909.02959">pdf</a>]  
                        [<a target="_blank"
                           href="https://github.com/shallowtoil/DROL">code</a>] <br>
                        <strong>Jinghao Zhou</strong>, Peng Wang, and Haoyang Sun. <br> 
                        <i>AAAI Conference on Artificial Intelligence (AAAI)</i>, 2020
                    </p></li></ul>
<!--                     <p class="abstract-text">
                        The problem of visual object tracking has traditionally been handled by variant tracking paradigms, either learning a model of the object's appearance exclusively online or matching the object with the target in an offline-trained embedding space. Despite the recent success, each method agonizes over its intrinsic constraint. The online-only approaches suffer from a lack of generalization of the model they learn thus are inferior in target regression, while the offline-only approaches (e.g., convontional siamese trackers) lack the video-specific context information thus are not discriminative enough to handle distractors. Therefore, we propose a parallel framework to integrate offline-trained siamese networks with a lightweight online module for enhance the discriminative capability. We further apply a simple yet robust template update strategy for siamese networks, in order to handle object deformation. Robustness can be validated in the consistent improvement over three siamese baselines: SiamFC, SiamRPN++, and SiamMask. Beyond that, our model based on SiamRPN++ obtains the best results over six popular tracking benchmarks. Though equipped with an online module when tracking proceeds, our approach inherits the high efficiency from siamese baseline and can operate beyond real-time.
                    </p> -->
                </div>
            </div>



            <h3>
                <a name="projects"></a> Projects
            </h3> 
            
            <div class="media">
                <div class="pull-left">
                    <img class="media-object" src="./assets/robotics/IFMV.png" width="125px" height="125px">
                </div>
                <div class="media-body">
                	<ul>
					<li><p class="media-heading">
                        <strong>
                            Information Fusion and Multi-dimention Vision on Wheeled Soccer Robot
                        </strong>
                        [<a target="_blank"
                           href="https://drive.google.com/open?id=1S0gSsbb45Fvkxh00GnFxqjcCFB7RuSZf">slide</a>]
                        [<a target="_blank"
                           href="https://github.com/hawking-npu/nubot_ws">code</a>]
                    </p>
                    <p class="abstract-text">
                        I designed a robost framework for our Middle Size League soccer-playing robots, which is majorly composed of omni-vision using GigE paranoma camera and front-vision using ZED RGB-D camera. This work achieved the real-time localization, mapping and object detection and it's done when I'm in <a target="_blank" href="https://github.com/hawking-npu">Wheeled Soccer Robot Base of Northwestern Polytechnical University@Hawking</a> for RoboCup competition.
                    </p></li></ul>
                </div>
            </div>
           
            <!--
             *** Reseach Interests ***
            -->
            <h3>
                <a name="Research Intreests"></a> Research Interests
            </h3>

            <div class="media">
            	<h4>Meta Learning</h4>
                <div class="pull-left">
                    <img class="media-object" src="./assets/cv/fewshot.jpg" width="150px" height="150px">
   				</div>
                <div class="media-body">
                    <p class="abstract-text">
                        Despite the recent success of deep neural networks, the high performance of these models often largely attributes to the large-volume training data, while the challenges still remain in the context of limited data. To address this issue, meta learning aims to learn a set of meta knowledge from data. In the area of supervised learning, this direction is also known as few-shot learning. 
                    </p>
                </div>
            </div>

            <div class="media">
            	<h4>Object Detection, Search and Tracking</h4>
                <div class="pull-left">
                    <img class="media-object" src="./assets/cv/SiamDW-Pytorch.png" width="150px" height="150px">
                </div>
                <div class="media-body">
                    <p class="abstract-text">
                        It's well known to us that object detection is a combinational task of object classification and object localization. While diverse pipelines and enhancement of object detecion has been extensively explored in recent years, relative tasks including few-shot object detection, general object search await further investigation. Object tracking, from a unified perspective, can be deemed as a task of object search in video level.
                    </p>
                </div>
            </div>
            <br>

            <!-- Footer
            ================================================== -->
            <footer class="footer">
                <div class='hidden-phone'>
                <h3><a name="wall"></a><strong>Gallery</strong></h3>
                <section id="photos">
                    <img src="./assets/ai/eye2.jpg">
                    <img src="./assets/rl/cs188.png">
                    <img src="./assets/kmeans.jpg"/>
                    <img src="./assets/cv/pic.png"/>
                    <img src="./assets/lena_1.bmp"/>
                    <img src="./assets/selfie/teaser.jpeg"/>
                    <img src="./assets/rl/mdp.png"/> 
                </section></div>

                <div class="row">
                    <div class="span12">
                        <p>
                            Modified from <a target="_blank" href="http://daggerfs.com/">© Yangqing Jia 2017</a>
                        </p>
                    </div>
                </div>

            </footer>
        </div>
    </div>
</div>
</body>
</html>